{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "# 시각화 \n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 등록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 리소스 등록 및 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_dataset_test = 'coco_trash_test'\n",
    "path_dataset = '/data/ephemeral/home/dataset/'\n",
    "path_output_eval = './output_eval'\n",
    "path_weights = 'model_final.pth'\n",
    "\n",
    "# 변경이 필요한 부분\n",
    "path_model_pretrained = 'COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml'\n",
    "model_title = path_model_pretrained.split(\"/\")[1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_cfg():\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(path_model_pretrained))\n",
    "    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, path_weights)\n",
    "    cfg.DATASETS.TEST = (coco_dataset_test,)\n",
    "\n",
    "    cfg.DATALOADER.NUM_WOREKRS = 4\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "    cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.5\n",
    "\n",
    "    cfg.MODEL.RPN.NMS_THRESH = 0.6\n",
    "\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if coco_dataset_test not in DatasetCatalog.list():\n",
    "    register_coco_instances(coco_dataset_test, {}, path_dataset + 'test.json', path_dataset)\n",
    "\n",
    "cfg = setup_cfg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# mapper - input data를 어떤 형식으로 return할지\n",
    "def MyMapper(dataset_dict):\n",
    "    \n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image = utils.read_image(dataset_dict['file_name'], format='BGR')\n",
    "    \n",
    "    dataset_dict['image'] = image\n",
    "    \n",
    "    return dataset_dict\n",
    "\n",
    "# test loader\n",
    "test_loader = build_detection_test_loader(cfg, coco_dataset_test, MyMapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output 뽑은 후 sumbmission 양식에 맞게 후처리 \n",
    "prediction_strings = []\n",
    "file_names = []\n",
    "\n",
    "class_num = 10\n",
    "\n",
    "for data in tqdm(test_loader):\n",
    "    \n",
    "    prediction_string = ''\n",
    "    \n",
    "    data = data[0]\n",
    "    \n",
    "    outputs = predictor(data['image'])['instances']\n",
    "    \n",
    "    targets = outputs.pred_classes.cpu().tolist()\n",
    "    boxes = [i.cpu().detach().numpy() for i in outputs.pred_boxes]\n",
    "    scores = outputs.scores.cpu().tolist()\n",
    "    \n",
    "    for target, box, score in zip(targets,boxes,scores):\n",
    "        prediction_string += (str(target) + ' ' + str(score) + ' ' + str(box[0]) + ' ' \n",
    "        + str(box[1]) + ' ' + str(box[2]) + ' ' + str(box[3]) + ' ')\n",
    "    \n",
    "    prediction_strings.append(prediction_string)\n",
    "    file_names.append(data['file_name'].replace(path_dataset,''))\n",
    "\n",
    "    # 시각화 코드\n",
    "    v = Visualizer(data['image'], MetadataCatalog.get(cfg.DATASETS.TEST[0]), scale=1.2)\n",
    "    out = v.draw_instance_predictions(outputs.to(\"cpu\"))\n",
    "\n",
    "    result_file = os.path.join(cfg.OUTPUT_DIR, f\"visualization_{data['file_name'].split('/')[-1]}\")\n",
    "    cv2.imwrite(result_file, out.get_image()[:, :, ::-1])\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission['image_id'] = file_names\n",
    "submission.to_csv(os.path.join(cfg.OUTPUT_DIR, f'submission_det_{model_title}.csv'), index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
